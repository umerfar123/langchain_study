{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1d0569",
   "metadata": {},
   "source": [
    "# Output Parsers\n",
    "\n",
    "    - Output parsers emerged as an early solution to the challenge of obtaining structured output from LLMs.\n",
    "\n",
    "    - Today, most LLMs support structured output natively. In such cases, using output parsers may be unnecessary, and you should leverage the model's built-in capabilities for structured output. Refer to the documentation of your chosen model for guidance on how to achieve structured output directly.\n",
    "\n",
    "    - Output parsers remain valuable when working with models that do not support structured output natively, or when you require additional processing or validation of the model's output beyond its inherent capabilities.\n",
    "\n",
    "    - Json Output Parser\n",
    "    - StrOutputParser\n",
    "    - StructuredOutputParser\n",
    "    - PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435658e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"qwen2.5-coder:7b\",\n",
    "    model_provider=\"ollama\",\n",
    "    temperature = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eaabb2",
   "metadata": {},
   "source": [
    "## StrOutputParser\n",
    "\n",
    "    - The StrOutputParser is the simplest output parser in Langchain. It is used to parse the output of a LLM and return it as a plain string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d3e2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Earth is the third planet from the Sun, with water covering 71% of its surface. It's known for its diverse ecosystems and is home to millions of species.\n",
      "<class 'langchain_core.messages.base.TextAccessor'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"you are a helpfull assistant, who answer in {output_limit} words, \\n {user_input}\",\n",
    "    input_variables=['output_limit','user_input']\n",
    ")\n",
    "\n",
    "query = 'explain about earth'\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "chain = template | model | str_parser\n",
    "\n",
    "response = chain.invoke({\n",
    "    'output_limit' : 20,\n",
    "    'user_input' : query\n",
    "})\n",
    "\n",
    "print()\n",
    "print(response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a331e2",
   "metadata": {},
   "source": [
    "## Json Output Parser\n",
    "\n",
    "    - Cannot Enforce Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af334b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Samantha Patel', 'age': 30, 'city': 'Mumbai'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(template=\"give me the name, age and city of fictional indian person \\n {format_instruction}\",\n",
    "                          input_variables=[],\n",
    "                          partial_variables={\"format_instruction\":parser.get_format_instructions()})\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "chain = template | model | json_parser\n",
    "response = chain.invoke({})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e78bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'black_hole_facts': [{'fact': 'Black holes are regions in space where the gravitational pull is so strong that nothing, not even light, can escape from them.'}, {'fact': 'The event horizon of a black hole is the boundary beyond which nothing can escape its gravity. It marks the point of no return for anything falling into the black hole.'}, {'fact': 'Black holes form when massive stars collapse in on themselves after they have exhausted their nuclear fuel. The core of these stars collapses under its own gravity, forming a singularity at the center.'}, {'fact': 'The first image of a black hole was captured by the Event Horizon Telescope (EHT) in 2019, showing the shadow cast by the supermassive black hole at the heart of the galaxy M87.'}, {'fact': 'Black holes can have varying masses, from small stellar black holes with masses similar to that of our Sun up to supermassive black holes found in the centers of galaxies, which can be millions or even billions of times more massive than the Sun.'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(template=\"give me 5 facts about black hole \\n {format_instruction}\",\n",
    "                          input_variables=[],\n",
    "                          partial_variables={\"format_instruction\":parser.get_format_instructions()})\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "chain = template | model | json_parser\n",
    "response = chain.invoke({})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b389ee",
   "metadata": {},
   "source": [
    "## StructuredOutputParser\n",
    "\n",
    "    - Can enforce schema\n",
    "    - No data validation\n",
    "    - Helps to extract structured JSON data from LLM responses based on predefined field schemas.\n",
    "    - It works by defining a list of fields(Response schema) that the model should return, ensuring the output follows a structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733a635",
   "metadata": {},
   "source": [
    "## PydanticOutputParser\n",
    "\n",
    "    - Strict Schema Enforcement\n",
    "    - Type Safety\n",
    "    - Easy Validation\n",
    "    - Seamless Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a6257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Samantha Patel' age=28 city='Mumbai'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Personschema(BaseModel):\n",
    "    name : str = Field(description='name of the person')\n",
    "    age : int = Field(gt=18, description='age of the person')\n",
    "    city : str = Field(description='name of thee city of the person belongs to')\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Personschema)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Generate name, age, city of fictional indian person \\n {format_instruction}',\n",
    "    input_variables=[],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "result = chain.invoke({})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422dd61",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env (3.13.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
