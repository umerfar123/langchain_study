{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5824c3d7",
   "metadata": {},
   "source": [
    "# Models\n",
    "- https://docs.langchain.com/oss/python/langchain/models\n",
    "- pip install -U langchain-openai\n",
    "- pip install -U langchain-ollama\n",
    "- pip install -U langchain-huggingface\n",
    "- pip install -U langchain-aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090cc4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73672856",
   "metadata": {},
   "source": [
    "    - Models Two Types\n",
    "        - Language Models\n",
    "            - LLMs(depreciating) : General purpose models that is used for raw text generation.\n",
    "            - Chat Models(new) : LLMs that are specialized for conversational task, fine tuned on chat datasets.\n",
    "    - Embedding Models\n",
    "\n",
    "![alt text](./Images/llm_vs_chatmodels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8410eb5",
   "metadata": {},
   "source": [
    "### Open source v/s closed models\n",
    "\n",
    "\n",
    "![alt text](./Images/opensource_vs_closed_models.png)\n",
    "\n",
    "\n",
    "    - Open source models are not finetuned, RLHF due to which its not good compared to closed models.\n",
    "    - Open source models weaker in instruciton following.\n",
    "    - Requires installation of dependencies like CUDA, transformers, pytorch etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a42d80",
   "metadata": {},
   "source": [
    "## Chatmodels\n",
    "\n",
    "    - Entry point to chat models : init_chat_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"qwen2.5-coder:7b\",\n",
    "    model_provider=\"ollama\",\n",
    "    temperature = 0.0\n",
    ")\n",
    "print(model.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea579b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "API_KEY = 'sfdfw231242fs'\n",
    "url = \"urrl\"\n",
    "model = init_chat_model(\n",
    "    model=\"qwen2.5-coder:7b\",\n",
    "    api_key= API_KEY, \n",
    "    base_url = url,\n",
    "    model_provider=\"ollama\",\n",
    "    temperature = 0.0\n",
    ")\n",
    "print(model.profile)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
